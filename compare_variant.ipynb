{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "available-tradition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Script to compare several variant calling csv file \n",
    "in the frame of Performance testing of plant virus \n",
    "(followong COST-DIVAS action).\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_percentage(freq):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if \"%\" in freq:\n",
    "        freq = float(freq.split(\"%\")[0])\n",
    "        freq = freq/100\n",
    "    return float(freq)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #TODO argparse use argument ?\n",
    "    #col_name = [\"Lab\", \"Type\", \"Reference\", \\\n",
    "    #    \"Allele\", \"Average_quality\",\"Personal validation\", \"Comment\", \"Input_file\", \\\n",
    "    #    \"Org_ref\", \"File_name\", \"Pos_1\", \"Pos_1\", \"Pos_2\", \"frequency_1\", \"frequency_2\"]\n",
    "    in_dir = \"/mnt/c/Users/johan/OneDrive/Bureau/INEXVIR_johan/PT3/Result\"\n",
    "    # in_file = \"PART_Cleanned_PT3.csv\"\n",
    "    #in_file = \"Cleanned_PT3.csv\"\n",
    "    in_file = \"Cleanned_PT3_1percent.csv\"\n",
    "   \n",
    "    #exp_file = \"Expected_result.csv\"\n",
    "    exp_file = \"Expected_result_1percent.csv\"\n",
    "\n",
    "    #clean_virus_data = pd.DataFrame(columns=col_name)\n",
    "    clean_virus_data = pd.DataFrame()\n",
    "    \n",
    "    input_path = os.path.join(in_dir, in_file)\n",
    "    exp_path = os.path.join(in_dir, exp_file)\n",
    "    \n",
    "    clean_virus_data = pd.read_csv(input_path, sep=\";\", header=0)\n",
    "    exp_virus_data = pd.read_csv(exp_path, sep=\";\", header=0)\n",
    "\n",
    "    print(\"Job done\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "trained-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8828\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_virus_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "small-toronto",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done\n",
      "0\n",
      "0\n",
      "8828\n"
     ]
    }
   ],
   "source": [
    "result_data2 = pd.DataFrame(columns=[\"Lab\", \"Sample\", \"Case\", \"Cov_1\", \"Freq_1\", \"Org_ref\", \n",
    "                                    \"Type\", \"Pos\", \"Ref\", \"Allele\", \"Validation\", \"Comment\"])\n",
    "data_virus = clean_virus_data.copy(deep=True)\n",
    "len_count=0\n",
    "len_count2=0\n",
    "list_uniq_ID = []\n",
    "\n",
    "\n",
    "def make_result_df(case, list_el, result_data2):\n",
    "    a_series  = pd.Series([list_el[0], list_el[1], case, list_el[3], list_el[4], list_el[5], \n",
    "        list_el[6], list_el[7], list_el[8], list_el[9], list_el[10], list_el[11]], index = result_data2.columns)\n",
    "    result_data2 = result_data2.append(a_series, ignore_index=True)\n",
    "    \n",
    "    return result_data2\n",
    "    \n",
    "for index2, row2 in data_virus.iterrows():\n",
    "    is_exp = False\n",
    "    is_nuc = False\n",
    "    is_pos = False\n",
    "    is_type = False\n",
    "    Correct_exp_validation_Yes = False\n",
    "    Wrong_exp_validation_No = False\n",
    "    Correct_nuc_validation_No = False\n",
    "    Wrong_nuc_validation_Yes = False\n",
    "    Correct_pos_validation_No = False\n",
    "    Wrong_pos_validation_Yes = False\n",
    "    Correct_type_validation_No = False\n",
    "    Wrong_type_validation_Yes = False\n",
    "    lab = row2[\"Lab\"]\n",
    "    Sample = row2[\"Input_file\"]\n",
    "    Cov_1 = row2[\"Cov_1\"]\n",
    "    Freq_1 = row2[\"frequency_1\"]\n",
    "    Org_ref = row2[\"Org_ref\"]\n",
    "    Type = row2[\"Type\"]\n",
    "    Pos = row2[\"Pos_1\"]\n",
    "    Ref = row2[\"Reference\"]\n",
    "    Allele = row2[\"Allele\"]\n",
    "    Validation = row2[\"Personal validation\"]\n",
    "    Comment = row2[\"Comment\"]\n",
    "    pos_list = [Pos, Pos+1, Pos-1]\n",
    "    \n",
    "    list_el = [lab, Sample, \"\", Cov_1, Freq_1, Org_ref, \n",
    "    Type, Pos, Ref, Allele, Validation, Comment]\n",
    "    for index, row_exp in exp_virus_data.iterrows():        \n",
    "        # if on the same sample (1,2 or 3)\n",
    "        if str(row_exp[\"Input_file\"]) == row2[\"Input_file\"][0]:\n",
    "            # use a limit of detection frequency\n",
    "            #if row_exp[\"frequency_1\"]>= 0.02:\n",
    "                # if mutation type identified is the same\n",
    "            if row_exp[\"Type\"] == row2[\"Type\"]:\n",
    "                # if position are the same\n",
    "                if row_exp[\"Pos_1\"] in pos_list:\n",
    "                    # if nucleotide change is the same                     \n",
    "                    if row_exp[\"Reference\"] == row2[\"Reference\"] and row_exp[\"Allele\"] == row2[\"Allele\"]:\n",
    "                        is_exp = True\n",
    "                        # if pass personal validation\n",
    "                        if row2[\"Personal validation\"] == \"Yes\":\n",
    "                            Correct_exp_validation_Yes = True\n",
    "\n",
    "                            break\n",
    "                        elif row2[\"Personal validation\"] == \"No\":    \n",
    "                            Wrong_exp_validation_No = True\n",
    "                            break\n",
    "                        else:\n",
    "                            break\n",
    "                    else: # ref or allele is different for same sample/type/Pos_1 (above Freq_limit)\n",
    "                        is_nuc = True\n",
    "                        #result_data2 = make_result_df(\"Wrong_nucleotide\", list_el, result_data2)\n",
    "                        if row2[\"Personal validation\"] == \"No\": \n",
    "                            Correct_nuc_validation_No = True\n",
    "                        elif row2[\"Personal validation\"] == \"Yes\": \n",
    "                            Wrong_nuc_validation_Yes = True\n",
    "                else: # Pos_1 is different for same sample/type (above Freq_limit)\n",
    "                    is_pos = True\n",
    "                    #result_data2 = make_result_df(\"Wrong_position\", list_el, result_data)\n",
    "                    if row2[\"Personal validation\"] == \"No\": \n",
    "                        Correct_pos_validation_No = True\n",
    "                    elif row2[\"Personal validation\"] == \"Yes\": \n",
    "                        Wrong_pos_validation_Yes = True\n",
    "\n",
    "            else: # Type is different for same sample\n",
    "                is_type = True\n",
    "                #result_data2 = make_result_df(\"Wrong_mutation_type\", list_el, result_data2)\n",
    "                if row2[\"Personal validation\"] == \"No\": \n",
    "                    Correct_type_validation_No = True\n",
    "                    break\n",
    "                elif row2[\"Personal validation\"] == \"Yes\": \n",
    "                    Wrong_type_validation_Yes = True\n",
    "\n",
    "                    break\n",
    "            #else: # Frequency is different for same sample/type\n",
    "                #pass\n",
    "        # if NOT on the same sample\n",
    "    # end of exp_virus_data loop\n",
    "    \n",
    "    if is_exp:\n",
    "        if Correct_exp_validation_Yes:\n",
    "            result_data2 = make_result_df(\"exp_Correct_validation_Yes\", list_el, result_data2)\n",
    "        elif Wrong_exp_validation_No:                                 \n",
    "            result_data2 = make_result_df(\"exp_Wrong_validation_No\", list_el, result_data2)\n",
    "        else:\n",
    "            result_data2 = make_result_df(\"exp_validation_unknown\", list_el, result_data2)\n",
    "    else:\n",
    "        if is_type:   \n",
    "            if Correct_type_validation_No: \n",
    "                result_data2 = make_result_df(\"type_Correct_validation_No\", list_el, result_data2)\n",
    "            elif Wrong_type_validation_Yes: \n",
    "                result_data2 = make_result_df(\"type_Wrong_validation_Yes\", list_el, result_data2)   \n",
    "            else:\n",
    "                result_data2 = make_result_df(\"type_validation_unknown\", list_el, result_data2)\n",
    "            continue\n",
    "        if is_nuc:  \n",
    "            if Correct_nuc_validation_No: \n",
    "                result_data2 = make_result_df(\"nuc_Correct_validation_No\", list_el, result_data2)\n",
    "            elif Wrong_nuc_validation_Yes: \n",
    "                result_data2 = make_result_df(\"nuc_Wrong_validation_Yes\", list_el, result_data2)\n",
    "            else:\n",
    "                result_data2 = make_result_df(\"nuc_validation_unknown\", list_el, result_data2)    \n",
    "            continue\n",
    "        if is_pos: \n",
    "            if Correct_pos_validation_No: \n",
    "                result_data2 = make_result_df(\"pos_Correct_validation_No\", list_el, result_data2)\n",
    "            elif Wrong_pos_validation_Yes: \n",
    "                result_data2 = make_result_df(\"pos_Wrong_validation_Yes\", list_el, result_data2)\n",
    "            else:\n",
    "                result_data2 = make_result_df(\"pos_validation_unknown\", list_el, result_data2)\n",
    "\n",
    "        \n",
    "\n",
    "# l_index_pos_allele == TPs\n",
    "# l_index_pos_al_validationY == TPsc == TPmv\n",
    "# l_index_pos_al_validationN == FNmv\n",
    "print(\"All done\")\n",
    "print(len_count)\n",
    "print(len_count2)\n",
    "print(len(result_data2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eligible-grant",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff022029c10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pivottablejs import pivot_ui\n",
    "\n",
    "pivot_ui(result_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "promotional-veteran",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n"
     ]
    }
   ],
   "source": [
    "for index, row in result_data2.iterrows():\n",
    "    Lab = row[\"Lab\"]\n",
    "    if Lab == \"H\":\n",
    "        if row[\"Sample\"] == \"2B\":\n",
    "            if row[\"Case\"] == \"exp_Correct_validation_Yes\":\n",
    "                pass\n",
    "                #print(row)\n",
    "print('pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "english-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq analysis done\n"
     ]
    }
   ],
   "source": [
    "# 0.6\t0.2\t0.126\t0.1\t0.06\t0.02\t0.01\n",
    "\n",
    "list_s1_pos_60p = [339, 900, 901, 902, 903, 904, 905, 906, 6336, 6337] #3\n",
    "list_s2_pos_60p = [861] #1\n",
    "list_s1_pos_20p = [2668, 319, 2191] #3\n",
    "list_s2_pos_20p = [4918] #1\n",
    "list_s3_pos_20p = [1983, 4031, 5067] #3 \n",
    "list_s3_pos_12p = [217, 2752] #2\n",
    "list_s1_pos_10p = [3830, 5439, 5440, 5894] #3\n",
    "list_s2_pos_10p = [339] #1\n",
    "list_s1_pos_06p = [2170, 3769, 3912] #3\n",
    "list_s2_pos_06p = [3830] #1\n",
    "list_s3_pos_06p = [5489, 4768, 3021, 3022, 3023, 3024, 925, 1646, 3390, 3391 ,3392, 3393] #6\n",
    "list_s1_pos_02p = [2672, 4090] #2\n",
    "list_s2_pos_02p = [2576] # 1\n",
    "list_s1_pos_01p = [3371, 6380, 6381, 6382, 2557] #3\n",
    "list_s2_pos_01p = [2916] #1\n",
    "list_s3_pos_01p = [1258, 1599, 1600, 1601, 1602, 1603, 2363, 2364, 2365, 2366] #3\n",
    "result_60p = pd.DataFrame(columns=[\"Lab\", \"Sample\", \"Pos\", \"Validation\", \"Freq\", \"Case\", \"Comment\"])\n",
    "result_20p = pd.DataFrame(columns=[\"Lab\", \"Sample\", \"Pos\", \"Validation\", \"Freq\", \"Case\", \"Comment\"])\n",
    "result_12p = pd.DataFrame(columns=[\"Lab\", \"Sample\", \"Pos\", \"Validation\", \"Freq\", \"Case\", \"Comment\"])\n",
    "result_10p = pd.DataFrame(columns=[\"Lab\", \"Sample\", \"Pos\", \"Validation\", \"Freq\", \"Case\", \"Comment\"])\n",
    "result_06p = pd.DataFrame(columns=[\"Lab\", \"Sample\", \"Pos\", \"Validation\", \"Freq\", \"Case\", \"Comment\"])\n",
    "result_02p = pd.DataFrame(columns=[\"Lab\", \"Sample\", \"Pos\", \"Validation\", \"Freq\", \"Case\", \"Comment\"])\n",
    "result_01p = pd.DataFrame(columns=[\"Lab\", \"Sample\", \"Pos\", \"Validation\", \"Freq\", \"Case\", \"Comment\"])\n",
    "\n",
    "count = 0\n",
    "\n",
    "list_sample = [\"1BE\", \"1BF\", \"1BG\", \"1CE\", \"1CF\", \"1CG\", \"1DE\", \"1DF\", \"1DG\", \"2BE\", \"2BF\", \"2BG\", \n",
    "               \"2CE\", \"2CF\", \"2CG\", \"2DE\", \"2DF\", \"2DG\", \"3BE\", \"3BF\", \"3BG\", \"3CE\", \"3CF\", \"3CG\", \n",
    "               \"3DE\", \"3DF\", \"3DG\"]\n",
    "list_case = [\"exp_Correct_validation_Yes\", \"exp_Wrong_validation_No\", \"exp_validation_unknown\"] #TPs\n",
    "for index, row in result_data2.iterrows():\n",
    "    case = row[\"Case\"]\n",
    "    if case in list_case:\n",
    "        freq = row[\"Freq_1\"]\n",
    "        position = row[\"Pos\"]\n",
    "        lab = row[\"Lab\"]\n",
    "        sample = row[\"Sample\"]\n",
    "        valid = row[\"Validation\"]\n",
    "        comment = row[\"Comment\"]\n",
    "        if sample in list_sample:\n",
    "            if sample.startswith(\"1\"):\n",
    "                for el in list_s1_pos_60p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_60p.columns)\n",
    "                        result_60p = result_60p.append(a_series, ignore_index=True)\n",
    "                for el in list_s1_pos_20p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_20p.columns)\n",
    "                        result_20p = result_20p.append(a_series, ignore_index=True)                   \n",
    "                for el in list_s1_pos_10p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_10p.columns)\n",
    "                        result_10p = result_10p.append(a_series, ignore_index=True) \n",
    "                for el in list_s1_pos_06p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_06p.columns)\n",
    "                        result_06p = result_06p.append(a_series, ignore_index=True) \n",
    "                for el in list_s1_pos_02p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_02p.columns)\n",
    "                        result_02p = result_02p.append(a_series, ignore_index=True) \n",
    "                for el in list_s1_pos_01p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_01p.columns)\n",
    "                        result_01p = result_01p.append(a_series, ignore_index=True)                     \n",
    "            if sample.startswith(\"2\"):\n",
    "                for el in list_s2_pos_60p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_60p.columns)\n",
    "                        result_60p = result_60p.append(a_series, ignore_index=True)\n",
    "                for el in list_s2_pos_20p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_20p.columns)\n",
    "                        result_20p = result_20p.append(a_series, ignore_index=True)                   \n",
    "                for el in list_s2_pos_10p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_10p.columns)\n",
    "                        result_10p = result_10p.append(a_series, ignore_index=True) \n",
    "                for el in list_s2_pos_06p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_06p.columns)\n",
    "                        result_06p = result_06p.append(a_series, ignore_index=True) \n",
    "                for el in list_s2_pos_02p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_02p.columns)\n",
    "                        result_02p = result_02p.append(a_series, ignore_index=True) \n",
    "                for el in list_s2_pos_01p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_01p.columns)\n",
    "                        result_01p = result_01p.append(a_series, ignore_index=True)\n",
    "            if sample.startswith(\"3\"):\n",
    "                for el in list_s3_pos_20p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_20p.columns)\n",
    "                        result_20p = result_20p.append(a_series, ignore_index=True) \n",
    "                for el in list_s3_pos_12p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_12p.columns)\n",
    "                        result_12p = result_12p.append(a_series, ignore_index=True)\n",
    "                for el in list_s3_pos_06p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_06p.columns)\n",
    "                        result_06p = result_06p.append(a_series, ignore_index=True) \n",
    "                for el in list_s3_pos_01p:\n",
    "                    if position == el or position == el+1 or position == el-1:\n",
    "                        a_series  = pd.Series([lab,sample,position,valid,freq,case,comment], index = result_01p.columns)\n",
    "                        result_01p = result_01p.append(a_series, ignore_index=True)        \n",
    "                \n",
    "print(\"freq analysis done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gothic-afternoon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"pivottablejs.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb8cf1591d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pivottablejs import pivot_ui\n",
    "\n",
    "pivot_ui(result_01p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
