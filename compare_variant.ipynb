{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "available-tradition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT3_snp_template_A.xlsx\n",
      "PT3_snp_template_lab_B.xlsx\n",
      "PT3_snp_template_C.xlsx\n",
      "PT3_snp_template_D.xlsx\n",
      "PT3_snp_template_labG.xlsx\n",
      "PT3_snp_template_H.xlsx\n",
      "PT3_snp_template_O.xlsx\n",
      "PT3_snp_template_Lab P.xlsx\n",
      "PT3_snp_templateQdraft_edited_ae_E.xlsx\n",
      "PT3_snp_templateQdraft_edited_ae_F.xlsx\n",
      "PT3_snp_templateQdraft_edited_ae_G.xlsx\n",
      "PT3_snp_templateQdraft_edited_ae_Q.xlsx\n",
      "PT3_snp_template_R.xlsx\n",
      "PT3_snp_template_filled_labS.xlsx\n",
      "PT3_snp_template_Lab T.xlsx\n",
      "PT3_snp_template_Y.xlsx\n",
      "PT3_snp_template_Z.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Script to compare several variant calling csv file \n",
    "in the frame of Performance testing of plant virus \n",
    "(followong COST-DIVAS action).\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_percentage(freq):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if \"%\" in freq:\n",
    "        freq = float(freq.split(\"%\")[0])\n",
    "        freq = freq/100\n",
    "    return float(freq)\n",
    "    \n",
    "def clean_data(new_df, clean_virus_data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    col_name = [\"Lab\", \"File_name\", \"Input_file\", \"Org_ref\", \"Position\", \\\n",
    "        \"Type\", \"Reference\",\"Allele\", \"Coverage\", \"Average_quality\", \\\n",
    "        \"Variant_frequency\", \"Personal_validation\", \"Comment\"]\n",
    "    clean_virus_tmp = pd.DataFrame(columns=col_name)\n",
    "    clean_virus_list = []\n",
    "    \n",
    "    # print(new_df.loc[new_df.index[pd.isna(new_df[\"File name\"])]])\n",
    "    dumb_list1 = []\n",
    "    dumb_list2 = []\n",
    "    dumb_list3 = []\n",
    "\n",
    "    # remove row when \"File name\" is null\n",
    "    update_df = new_df.drop(new_df.index[pd.isna(new_df[\"File name\"])])\n",
    "\n",
    "    for index, row in update_df.iterrows():\n",
    "        ######## file name column\n",
    "        el = row[\"File name\"]\n",
    "        data = el.split(\"_\")\n",
    "        input_file_data = str(data[0] + \"_\" + data[1])\n",
    "        org_ref_data = data[-1]\n",
    "        if \".\" in org_ref_data:\n",
    "            org_ref_data = org_ref_data.split(\".\")[0]\n",
    "        if \" \" in org_ref_data:\n",
    "            org_ref_data = org_ref_data.split(\" \")[0]\n",
    "        file_name = str(input_file_data + \"_\" + org_ref_data )\n",
    "        update_df.loc[index,\"Input_file\"] = input_file_data\n",
    "        update_df.loc[index,\"Org_ref\"] = org_ref_data\n",
    "        update_df.loc[index,\"File_name\"] = file_name\n",
    "        ########\n",
    "        ######## Position column\n",
    "        el = str(row[\"Position\"])\n",
    "        if \"..\" in el:\n",
    "            pos1 = int(float(el.split(\"..\")[0]))\n",
    "            pos2 = int(float(el.split(\"..\")[1]))\n",
    "        elif \"^\" in el:\n",
    "            pos1 = int(float(el.split(\"^\")[0]))\n",
    "            pos2 = int(float(el.split(\"^\")[1]))      \n",
    "        elif pd.isna(row[\"Position\"]):\n",
    "            pos1 = None\n",
    "            pos2 = None\n",
    "        else:\n",
    "            pos1 = int(float(el))\n",
    "            pos2 = None\n",
    "        update_df.loc[index,\"Pos_1\"] = pos1\n",
    "        update_df.loc[index,\"Pos_2\"] = pos2\n",
    "        ########\n",
    "        ######## Coverage column       \n",
    "        el = str(row[\"Coverage\"])\n",
    "        if \"->\" in el:\n",
    "            cov1 = int(float(el.split(\"->\")[0]))\n",
    "            cov2 = int(float(el.split(\"->\")[1]))\n",
    "        elif \"^\" in el:\n",
    "            cov1 = int(float(el.split(\"^\")[0]))\n",
    "            cov2 = int(float(el.split(\"^\")[1]))\n",
    "        elif \"..\" in el:\n",
    "            cov1 = int(float(el.split(\"..\")[0]))\n",
    "            cov2 = int(float(el.split(\"..\")[1]))            \n",
    "        elif pd.isna(row[\"Coverage\"]):\n",
    "            cov1 = None\n",
    "            cov2 = None\n",
    "        else:\n",
    "            cov1 = int(float(el))\n",
    "            cov2 = None\n",
    "        update_df.loc[index,\"Cov_1\"] = cov1\n",
    "        update_df.loc[index,\"Cov_2\"] = cov2\n",
    "        ########\n",
    "        ######## Variant frequency  \n",
    "        lab_percent_list = [\"B\", \"H\", \"O\", \"Q\", \"Y\"]\n",
    "        el = str(row[\"Variant Frequency\"])\n",
    "        if \",\" in el:\n",
    "            el = el.replace(\",\", \".\")\n",
    "        if \"->\" in el:\n",
    "            freq1 = el.split(\"->\")[0]\n",
    "            freq1 = make_percentage(freq1)\n",
    "            freq2 = el.split(\"->\")[1]\n",
    "            freq2 = make_percentage(freq2)\n",
    "        elif \"^\" in el:\n",
    "            freq1 = el.split(\"^\")[0]\n",
    "            freq1 = make_percentage(freq1)\n",
    "            freq2 = el.split(\"^\")[1]\n",
    "            freq2 = make_percentage(freq2)\n",
    "        elif \"..\" in el:\n",
    "            freq1 = el.split(\"..\")[0]\n",
    "            freq1 = make_percentage(freq1)\n",
    "            freq2 = el.split(\"..\")[1]   \n",
    "            freq2 = make_percentage(freq2)\n",
    "        elif pd.isna(row[\"Variant Frequency\"]):\n",
    "            freq1 = None\n",
    "            freq2 = None\n",
    "        else:\n",
    "            freq1 = el\n",
    "            freq1 = make_percentage(freq1)\n",
    "            freq2 = None\n",
    "            \n",
    "        if str(row[\"Lab\"]) in lab_percent_list:\n",
    "            if freq1 != None:\n",
    "                freq1 = float(freq1)/100\n",
    "            if freq2 != None:\n",
    "                freq2 = float(freq2)/100\n",
    "            \n",
    "        update_df.loc[index,\"frequency_1\"] = freq1\n",
    "        update_df.loc[index,\"frequency_2\"] = freq2        \n",
    "        \n",
    "        dumb_list1.append(el)\n",
    "        dumb_list2.append(input_file_data)\n",
    "        dumb_list3.append(org_ref_data)\n",
    "    \n",
    "    #update_df = update_df.drop([\"File name\"], axis=1)\n",
    "    # print(\"File name\")\n",
    "    # print(set(dumb_list1))  \n",
    "    # print(\"input_file_data\")\n",
    "    # print(set(dumb_list2))   \n",
    "    # print(\"org_ref_data\")\n",
    "    # print(set(dumb_list3))    \n",
    "    clean_virus_data = clean_virus_data.append(update_df, ignore_index=True)\n",
    "    # print(clean_virus_data)\n",
    "\n",
    "    return clean_virus_data\n",
    "\n",
    "def open_file(full_path, col_name, lab_dir, clean_virus_data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # print(full_path)\n",
    "    xls = pd.ExcelFile(full_path, engine='openpyxl')\n",
    "    sheet_list = xls.sheet_names\n",
    "    for sheet in sheet_list:\n",
    "        # print(sheet)\n",
    "        virus_data = pd.read_excel(full_path, engine='openpyxl', sheet_name=sheet)\n",
    "        virus_data.insert(0,\"Lab\", lab_dir)\n",
    "        selected_columns = virus_data[col_name]\n",
    "        new_df = selected_columns.copy()\n",
    "        clean_virus_data = clean_data(new_df, clean_virus_data)\n",
    "    return clean_virus_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #TODO argparse use argument ?\n",
    "    col_name = [\"Lab\", \"File name\", \"Position\", \\\n",
    "        \"Type\", \"Reference\",\"Allele\", \"Coverage\", \"Average quality\", \\\n",
    "        \"Variant Frequency\", \"Personal validation\", \"Comment\"]\n",
    "\n",
    "    out_dir = \"/mnt/c/Users/johan/OneDrive/Bureau/bioinfo/PT3/Result/variant_calling/\"\n",
    "    lab_dir = out_dir\n",
    "    clean_virus_data = pd.DataFrame(columns=col_name)\n",
    "    \n",
    "    for lab_dir in os.listdir(out_dir):\n",
    "        #print(lab_dir)\n",
    "        \n",
    "        filename_list = os.listdir(os.path.join(out_dir, lab_dir))\n",
    "        #filename_list = os.listdir(out_dir)\n",
    "        for filename in filename_list:\n",
    "            if filename.startswith(\"PT3_snp_template\"):\n",
    "                print(filename)\n",
    "                full_path = os.path.join(os.path.join(out_dir, lab_dir),filename)\n",
    "                # full_path = os.path.join(out_dir,filename)\n",
    "                clean_virus_data = open_file(full_path, col_name, lab_dir, clean_virus_data)\n",
    "        \n",
    "        clean_virus_data = clean_virus_data.drop([\"File name\"], axis=1)\n",
    "        clean_virus_data = clean_virus_data.drop([\"Position\"], axis=1)\n",
    "        clean_virus_data = clean_virus_data.drop([\"Coverage\"], axis=1)\n",
    "        clean_virus_data = clean_virus_data.drop([\"Variant Frequency\"], axis=1)\n",
    "        \n",
    "    #print(clean_virus_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "medical-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rint(clean_virus_data.groupby(\"Lab\")['frequency_1'].max())\n",
    "\n",
    "#print(clean_virus_data[\"frequency_1\"].unique())\n",
    "#print(len(clean_virus_data[\"frequency_1\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "commercial-tablet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "max_nb = float(0)\n",
    "min_nb = float(1)\n",
    "for index, element in clean_virus_data.iterrows():\n",
    "    if not pd.isna(element[\"frequency_1\"]):\n",
    "        a = element[\"frequency_1\"]\n",
    "        if max_nb < a:\n",
    "            max_nb = a\n",
    "        if min_nb > a:\n",
    "            min_nb = a\n",
    "                \n",
    "\n",
    "        \n",
    "        #if element[\"Lab\"] == \">=\":\n",
    "            #print(element[\"Lab\"])\n",
    "            #print(index)\n",
    "            #print(element.loc[index, \"File_name\"])\n",
    "            #count+=1\n",
    "            \n",
    "            #print(clean_virus_data.iloc[[str(int(index-1))]])\n",
    "        \n",
    "print(max_nb)\n",
    "print(min_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "completed-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "#print(clean_virus_data.File_name.unique())\n",
    "print(len(clean_virus_data.File_name.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "characteristic-newsletter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lab</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Allele</th>\n",
       "      <th>Average quality</th>\n",
       "      <th>Personal validation</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Input_file</th>\n",
       "      <th>Org_ref</th>\n",
       "      <th>File_name</th>\n",
       "      <th>Pos_1</th>\n",
       "      <th>Pos_2</th>\n",
       "      <th>Cov_1</th>\n",
       "      <th>Cov_2</th>\n",
       "      <th>frequency_1</th>\n",
       "      <th>frequency_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_1BA</td>\n",
       "      <td>DQ000985</td>\n",
       "      <td>dataset_1BA_DQ000985</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5339.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_1CA</td>\n",
       "      <td>DQ000985</td>\n",
       "      <td>dataset_1CA_DQ000985</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_1DA</td>\n",
       "      <td>DQ000985</td>\n",
       "      <td>dataset_1DA_DQ000985</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_1BE</td>\n",
       "      <td>DQ000985</td>\n",
       "      <td>dataset_1BE_DQ000985</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5268.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dataset_1CE</td>\n",
       "      <td>DQ000985</td>\n",
       "      <td>dataset_1CE_DQ000985</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5746.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.191</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lab      Type Reference Allele Average quality Personal validation Comment  \\\n",
       "0   A  Deletion         G    NaN              36                 Yes     NaN   \n",
       "1   A  Deletion         G    NaN              36                 Yes     NaN   \n",
       "2   A  Deletion         G    NaN              36                 Yes     NaN   \n",
       "3   A  Deletion         G    NaN              36                 Yes     NaN   \n",
       "4   A  Deletion         G    NaN              35                 Yes     NaN   \n",
       "\n",
       "    Input_file   Org_ref             File_name  Pos_1  Pos_2   Cov_1  Cov_2  \\\n",
       "0  dataset_1BA  DQ000985  dataset_1BA_DQ000985  319.0    NaN  5339.0    NaN   \n",
       "1  dataset_1CA  DQ000985  dataset_1CA_DQ000985  319.0    NaN  5783.0    NaN   \n",
       "2  dataset_1DA  DQ000985  dataset_1DA_DQ000985  319.0    NaN  5783.0    NaN   \n",
       "3  dataset_1BE  DQ000985  dataset_1BE_DQ000985  319.0    NaN  5268.0    NaN   \n",
       "4  dataset_1CE  DQ000985  dataset_1CE_DQ000985  319.0    NaN  5746.0    NaN   \n",
       "\n",
       "   frequency_1  frequency_2  \n",
       "0        0.196          NaN  \n",
       "1        0.189          NaN  \n",
       "2        0.189          NaN  \n",
       "3        0.198          NaN  \n",
       "4        0.191          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_virus_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eligible-grant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b658c970fe4671a9715fab7211df46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qgrid\n",
    "\n",
    "A = qgrid.show_grid(clean_virus_data)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confidential-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G' 'A' nan 'C' 'T' 'AC' 'TG' 'CT' 'CAAC' 'W' '-' 'AA' '/' 'ACT' 'TC'\n",
      " 'GC' 'TT' 'CA' 'CG' 'AT' 'GAG' 'CAA' 'AAG' 'TA' 'CCG' 'CTT' 'CC' 'GT'\n",
      " 'GA' 'ACAC' 'GGT' 'AAA' 'AGC' 'CAAA' 'GG' 'CCC' 'GTGT' 'AGT' 'ATG' 'AG'\n",
      " 'CGT' 'U' 'GCT']\n"
     ]
    }
   ],
   "source": [
    "print(clean_virus_data.Reference.unique())\n",
    "#clean_virus_data.to_csv(\"/mnt/c/Users/johan/OneDrive/Bureau/test_PT3.csv\", index=False, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-paraguay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
